# GridWorld - Reinforcement Learning with Value Iteration

## ğŸ“ Project Overview

This project implements a GridWorld environment for Reinforcement Learning, utilizing Value Iteration to compute the optimal policy. The environment is deployed using Flask and provides an interactive front-end for users to define the grid, select start and end points, place obstacles, and visualize the computed optimal policy.

## ğŸ“ŒProject Prompt  

please modify code from HW1-2 to be Value iteration and shows the best way from start point to end point.

## âœ¨ Features

ğŸš€ Value Iteration Algorithm to solve the GridWorld problem.

ğŸ¨ Interactive Web UI built with HTML, JavaScript, and jQuery.

ğŸ”§ Flask Backend API for computing value matrices and policies.

ğŸ“ Customizable Grid Size (3Ã—3 to 10Ã—10).

ğŸ— Dynamic Obstacle Placement to experiment with different scenarios.

ğŸ“Š Real-time Visualization of the value and policy matrices.

## ğŸ›  Installation

Prerequisites

Ensure you have the following installed:

Python 3.x

Flask

NumPy

Steps

Clone this repository:

git clone 

cd GridWorld

Install dependencies:

pip install flask numpy

Run the application:

python app.py

Open your browser and navigate to:

http://127.0.0.1:5000/

## ğŸ® Usage

Enter the grid size (between 3 and 10) and click Generate Grid.

Click on a cell to select the Start Point (Green).

Click another cell to select the End Point (Red).

Click additional cells to place Obstacles (Gray).

Click Run Value Iteration to compute the optimal policy.

View the Value Matrix and Policy Matrix.

## ğŸ“‚ File Structure

GridWorld/
â”‚â”€â”€ app.py                # Flask backend for computation
â”‚â”€â”€ templates/
â”‚   â”œâ”€â”€ gridworld.html    # Front-end UI
â”‚â”€â”€ static/               # (Optional) For additional CSS/JS files
â”‚â”€â”€ README.md             # Documentation

## âš™ï¸ How It Works

The Value Iteration Algorithm updates state values iteratively using the Bellman equation until convergence.

The computed value matrix provides an estimate of the expected reward from each state.

The policy matrix defines the optimal action to take from each state.

The front-end visually represents the computed optimal path.

## ğŸ“Š Example Grid Visualization

5Ã—5 Grid Example:
S â†’ â†’ â†’ â†’
â†‘ X X X â†“
â†‘ â† â† â† â†“
â†‘ X X X â†“
â†‘ â†’ â†’ â†’ E

(S = Start, E = End, X = Obstacle, Arrows indicate optimal policy)

## ğŸ™Œ Acknowledgments

Inspired by classic GridWorld reinforcement learning problems.

Implemented using Flask and jQuery for interactive visualization.

## Demo Pictrue

![image](https://github.com/yao790609/RL_HW2/blob/main/Demo.jpg)

